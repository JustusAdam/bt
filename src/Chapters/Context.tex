% Chapter Template

\chapter{Context handling} % Main chapter title

\label{ChapterContext} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------

\section{What is Context?}

A context, as far as Ohua is concerned, is a programming construct which changes the behavior of subsequent sections of code.
As an example the most basic context is the root context of an ohua \textt{algo} which changes the behavior of the functions within in so far as that they are executed once for each time the algo is executed.
Another example is the \texttt{smap} context which casues functions within to be executet multiple times.
Both of these contexts are control flow contexts which means they alter whether and how often functions are executed.
Most contexts in ohua are represented as a pair of encapsulating operators which mark the beginning and end of the context respectively and the context itself influences the operators in between.
The beginning marker sets up the altered behaviour and the end marker restores the original behavior.

In case of the \texttt{algo} context the \texttt{algo-in} as start operator starts the execution and the \texttt{algo-out} operator as end operator collects the result.
For \texttt{smap} the \texttt{smap} operator starts by executing the algorithm within once for each element in the structure being mapped and the \texttt{collect} operator restores the old behavior by waiting for as many elements as were in the mapped structure before returning them collectively to the next part of the program.

\subsection{Arising problems}


Control flow altering context such as smap or if pose a problem for yauhau.
The idea behind our batching transformation is to find sets of pairiwise independant fetches and replacing them with a single, accumulated (batched) fetch.
The accumulator would execute all fetches at once and return the results back into the appropriate place in the graph.
However it is a simple operator and has to wait for all inputs before executing.
This would pose an issue, were one of its inputs coming from the branch of a conditional, such as if.
If the branch in question was not selected at runtime the input to the accumulator would be missing, preventing it from executing any of the fetches.
Similarly with the map operation smap.
Were one of the inputs to the accumulator originating from inside an smap the input could get several values instead of just one, a situation which the naive accumulator is unable to cope with.
As a result we need to ensure all inputs to an accumulator are present at the same time and in the same quantity.
In turn this means each of the pairwise parallel fetches has to be called the same number of times.
The simplest way to do this is to remove all control flow context around a fetch operation, leaving it in the root context.
Here we are guaranteed that any fetch will only ever be executed once.

I should mention that there is an alternative strategy for handling this but it would require runtime scheduling.
Scheduling offers more flexibility but at the same time also poses a substantially larger runtime overhead.
Because of this we opted for a compile time rewrite approach.

Haxl and muse both use runtime techniques to tackle this problem.
In the case of Haxl it leverages the Haskell runtime (scheduler) whereas muse relies on a runtime AST and traversals on this AST.

\subsubsection{}

%-----------------------------------
%	SUBSECTION 1
%-----------------------------------
\subsection{Definition}

We define

%-----------------------------------
%	SUBSECTION 2
%-----------------------------------
