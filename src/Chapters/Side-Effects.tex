%!TEX root = ../thesis.tex
\chapter{Side Effects}
\label{ch:side-effects}

% TODO
% Figure 8.1 is never referenced or explained in the text.
% “These are typical semantics as would be expected of a program written in a non-sequential language like Haskell.” -> true, which breaks modularity and it breaks the batching of Haxl across functions as argued in our paper.
% 8.4: would benefit from describing the algorithm either in pseudo-code or Clojure code. section seems incomplete because you do not explain the final rewrite.

In the application domain of \yauhau{}, which is a program that accesses a remote resource, like a database or some repository over the network, side effects are actions which modify the remote resource.
They are called side effects because they violate the rules of referential transparency.
Referential transparency is a property of pure functions and means that the result of a computation does not change, if the call sites of the referentially transparent functions are replaced by their result.
In \yauhau{} we make the assumption that, even though we do not control the implementation of the fetch performed by the data source or have control over the remote source, read requests are pure actions.
This allows us to cache results and remove duplicate requests.
In practice the remote resource may of course change as the program runs which is why we allow the programmer to choose an appropriate caching strategy with the desired tradeoff between performance and error.

\section{Current implementation}

This behaviour is similar to the behaviour of Haxl, which also caches fetch results and removes duplicate requests.
We however wanted to go one step further and provide the user with the ability to perform transformative actions on the remote resource during execution.
Effectful actions are of course already supported by Ohua, however as mentioned before it breaks the assumptions made by \yauhau{}.
Therefore the programmer would either have to accept the possibility of errors or relinquish the use of a cache, which has profound impacts on performance.

We solve this issue in \yauhau{} by specifically implementing write requests.
These special \texttt{write} operators are not only able to access the network in a user defined way, but it also informs the cache of the performed request.
When the user defines a cache he can also provide a function for how to manipulate the cache as a result of this request.
Two simple predefined actions are available by default \texttt{dropOne} and \texttt{dropAll}.
The former drops a request from the cache matching the current one and the latter clears the entire cache.

\begin{figure}
\begin{minted}{Java}
/* Caches should implement both interfaces */
public interface Dropable<A> {
    Dropable<A> dropOne(A a);

    Dropable<A> dropAll();
}

public interface Cache {
    BiFunction<Dropable<Request>, Request, Dropable<Request>>
    getRemoveAction();
    Object get(Request r);
    Object set(Request r, Object resp);
    void handleStore(Request r);
    int cacheSize();
}
\end{minted}
\caption{The cache interface}
\label{fig:the-cache-interface}
\end{figure}

\section{Enforcing intra algorithm order}

This allows programmers to obtain correct read-write semantics, however it still poses an issue due to ordering.
In Ohua order of execution is only guaranteed for operators with explicit data dependencies.
In the example in Figure~\ref{fig:independent-actions-code} for instance it is entirely indeterministic whether the read or write is going to be executed first.
This problem can be avoided by using an operator called \texttt{seq}.
\texttt{seq} enforces its first argument to be fully evaluated before allowing its second argument to be evaluated.
In the example Figure~\ref{fig:enforcing-order-with-seq} we enforce the write to happen first using seq.

\begin{figure}
\begin{minted}{Clojure}
(defalgo reqs [req]
  (let [_ (write req)
        r (read req)]
    r))
\end{minted}
\caption{Example for if independent actions}
\label{fig:independent-actions-code}
\end{figure}

\begin{figure}
\begin{minted}{Clojure}
(defalgo reqs [req]
  (let [w (write req)
        r (seq w (read req))]
    r))
\end{minted}
\caption{Enforcing order using seq}
\label{fig:enforcing-order-with-seq}
\end{figure}

\begin{figure}
\begin{minted}{Clojure}
(defalgo req [req]
  (read (write req)))
\end{minted}
\caption{Enforcing order with data dependencies}
\label{fig:enforcing-order-with-dd}
\end{figure}

We could also achieve the same semantics by introducing data dependencies between the two function calls as seen in Figure~\ref{fig:enforcing-order-with-dd}.
These are typical semantics as would be expected of a program written in a non sequential language like Haskell.
However one problem still remains.

\section{Enforcing order inter algorithm}

What if we have a similar situation as above, but the read and write requests are in two algorithms?
An example of this may be seen in Figure~\ref{fig:reads-and-writes-in-algos}.
Here we have basically the same situation as above, but this time the programmer tried to introduce the data dependency by making one algorithm depend on the result of the other.
By normal semantics this should work, however in Ohua all algorithms are directly spliced into the main program except two boundary operators called \texttt{algo-in} and \texttt{algo-out}.
The boundary operators however only track in and output to the alorithm.
An independent fetch like the one we have here in \texttt{does-read} has no data dependency to the algorithm boundary.
As the result of our write request is only connected to the algorithm boundary via a parameter there is no data dependency between the read and the write request after splicing.
If as a result the order of the read and write request was nondeterministic it would be very counter intuitive to the programmer.
He would expect regular program semantics to hold in this case, which they do not do.
There is of course still the \texttt{seq} operator, which we could use to enforce ordering and those semantics actually hold, even across algorithms, but require additional work from the programmer.
Therefore we would like to automate the addition of \texttt{seq} operators in the program where there are independent reads or writes that may cause unexpected indeterminism.

\begin{figure}
\begin{minted}{Clojure}
(defalgo does-read [req some-data]
  (let [res (read some-constant)]
    (computation res req some-data)))

(defalgo does-write [req]
  (write req))

(defalgo reqs [req]
  (does-read req (does-write req)))
\end{minted}
\caption{Reads and writes in algorithms}
\label{fig:reads-and-writes-in-algos}
\end{figure}

\section{Rewrite}

Fundamentally we only need to \texttt{seq} algorithms together when we have one of the typical read after write, write after write or read before write conflicts and the latter operator is data independent from the former.
Therefore we must first identify the dependency relationships between the algorithms.

We build a directed graph of data dependencies between algorithms by first finding all distinct algorithm context frames which have been assigned in the dataflow graph of our program.
These context frames become the nodes of our dependency graph, which is a directed graph where edges represent data flowing from the source algorithm to the target algorithm.
Edges are calculated by first finding a algo exit nodes, called \texttt{algo-out}.
From an \texttt{algo-out} node we traverse the data dependencies of the program graph downwards until we either

\begin{itemize}
  \item encounter an \texttt{algo-in} node, in which case we insert an edge from the algorithm belonging to the \texttt{algo-out} node we started from to the algorithm belonging to the \texttt{algo-in} node we just encountered, into the dependency graph.
    We do not explore this path further since following dependencies are guaranteed to be covered by transitive relationships.
  \item encounter an \texttt{algo-out} node, in which case we are nested in another algorithm and we stop exploring this path since subsequent dependencies are covered by the enclosing algorithm.
\end{itemize}

Thus we obtain a version of a dataflow graph which only shows data dependencies between algorithms.

Following that we assign labels to each algorithm indicating whether the algorithm in question performs reads and, or writes.
This is done by compiling sets of algos with reads and writes.
I filter the IR function list for \texttt{fetch} and \texttt{write} nodes.
Map each node to its associated algo contexts, concatenate these and finally remove duplicate entries.
Now we have a set of read and write performing algos respectively.
Each algorithm in the graph is then labeled with \texttt{:does-read} and \texttt{:does-write} depending on which set it is member of.
